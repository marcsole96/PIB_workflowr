<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>PiB</title>

<script src="site_libs/header-attrs-2.7/header-attrs.js"></script>
<script src="site_libs/jquery-3.5.1/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cosmo.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/textmate.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<script src="site_libs/htmlwidgets-1.5.3/htmlwidgets.js"></script>
<script src="site_libs/plotly-binding-4.9.3/plotly.js"></script>
<script src="site_libs/typedarray-0.1/typedarray.min.js"></script>
<link href="site_libs/crosstalk-1.1.1/css/crosstalk.css" rel="stylesheet" />
<script src="site_libs/crosstalk-1.1.1/js/crosstalk.min.js"></script>
<link href="site_libs/plotly-htmlwidgets-css-1.57.1/plotly-htmlwidgets.css" rel="stylesheet" />
<script src="site_libs/plotly-main-1.57.1/plotly-latest.min.js"></script>
<link href="site_libs/font-awesome-5.1.0/css/all.css" rel="stylesheet" />
<link href="site_libs/font-awesome-5.1.0/css/v4-shims.css" rel="stylesheet" />

<link rel="icon" href="https://github.com/workflowr/workflowr-assets/raw/master/img/reproducible.png">
<!-- Add a small amount of space between sections. -->
<style type="text/css">
div.section {
  padding-top: 12px;
}
</style>



<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>








<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.tab('show');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row">
<div class="col-sm-12 col-md-4 col-lg-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-sm-12 col-md-8 col-lg-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">PIB_workflowr</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li>
  <a href="PiB.html">PiB</a>
</li>
<li>
  <a href="about.html">About</a>
</li>
<li>
  <a href="license.html">License</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="https://github.com/marcsole96/PIB_workflowr">
    <span class="fas fa-github"></span>
     
    Source code
  </a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">



<h1 class="title toc-ignore">PiB</h1>

</div>


<p>
<button type="button" class="btn btn-default btn-workflowr btn-workflowr-report" data-toggle="collapse" data-target="#workflowr-report">
<span class="glyphicon glyphicon-list" aria-hidden="true"></span> workflowr <span class="glyphicon glyphicon-ok text-success" aria-hidden="true"></span>
</button>
</p>
<div id="workflowr-report" class="collapse">
<ul class="nav nav-tabs">
<li class="active">
<a data-toggle="tab" href="#summary">Summary</a>
</li>
<li>
<a data-toggle="tab" href="#checks"> Checks <span class="glyphicon glyphicon-ok text-success" aria-hidden="true"></span> </a>
</li>
<li>
<a data-toggle="tab" href="#versions">Past versions</a>
</li>
</ul>
<div class="tab-content">
<div id="summary" class="tab-pane fade in active">
<p>
<strong>Last updated:</strong> 2021-10-12
</p>
<p>
<strong>Checks:</strong> <span class="glyphicon glyphicon-ok text-success" aria-hidden="true"></span> 7 <span class="glyphicon glyphicon-exclamation-sign text-danger" aria-hidden="true"></span> 0
</p>
<p>
<strong>Knit directory:</strong> <code>PIB_workflowr/data/</code> <span class="glyphicon glyphicon-question-sign" aria-hidden="true" title="This is the local directory in which the code in this file was executed."> </span>
</p>
<p>
This reproducible <a href="http://rmarkdown.rstudio.com">R Markdown</a> analysis was created with <a
  href="https://github.com/jdblischak/workflowr">workflowr</a> (version 1.6.2). The <em>Checks</em> tab describes the reproducibility checks that were applied when the results were created. The <em>Past versions</em> tab lists the development history.
</p>
<hr>
</div>
<div id="checks" class="tab-pane fade">
<div id="workflowr-checks" class="panel-group">
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongRMarkdownfilestronguptodate"> <span class="glyphicon glyphicon-ok text-success" aria-hidden="true"></span> <strong>R Markdown file:</strong> up-to-date </a>
</p>
</div>
<div id="strongRMarkdownfilestronguptodate" class="panel-collapse collapse">
<div class="panel-body">
<p>Great! Since the R Markdown file has been committed to the Git repository, you know the exact version of the code that produced these results.</p>
</div>
</div>
</div>
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongEnvironmentstrongempty"> <span class="glyphicon glyphicon-ok text-success" aria-hidden="true"></span> <strong>Environment:</strong> empty </a>
</p>
</div>
<div id="strongEnvironmentstrongempty" class="panel-collapse collapse">
<div class="panel-body">
<p>Great job! The global environment was empty. Objects defined in the global environment can affect the analysis in your R Markdown file in unknown ways. For reproduciblity it’s best to always run the code in an empty environment.</p>
</div>
</div>
</div>
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongSeedstrongcodesetseed20210909code"> <span class="glyphicon glyphicon-ok text-success" aria-hidden="true"></span> <strong>Seed:</strong> <code>set.seed(20210909)</code> </a>
</p>
</div>
<div id="strongSeedstrongcodesetseed20210909code" class="panel-collapse collapse">
<div class="panel-body">
<p>The command <code>set.seed(20210909)</code> was run prior to running the code in the R Markdown file. Setting a seed ensures that any results that rely on randomness, e.g. subsampling or permutations, are reproducible.</p>
</div>
</div>
</div>
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongSessioninformationstrongrecorded"> <span class="glyphicon glyphicon-ok text-success" aria-hidden="true"></span> <strong>Session information:</strong> recorded </a>
</p>
</div>
<div id="strongSessioninformationstrongrecorded" class="panel-collapse collapse">
<div class="panel-body">
<p>Great job! Recording the operating system, R version, and package versions is critical for reproducibility.</p>
</div>
</div>
</div>
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongCachestrongnone"> <span class="glyphicon glyphicon-ok text-success" aria-hidden="true"></span> <strong>Cache:</strong> none </a>
</p>
</div>
<div id="strongCachestrongnone" class="panel-collapse collapse">
<div class="panel-body">
<p>Nice! There were no cached chunks for this analysis, so you can be confident that you successfully produced the results during this run.</p>
</div>
</div>
</div>
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongFilepathsstrongrelative"> <span class="glyphicon glyphicon-ok text-success" aria-hidden="true"></span> <strong>File paths:</strong> relative </a>
</p>
</div>
<div id="strongFilepathsstrongrelative" class="panel-collapse collapse">
<div class="panel-body">
<p>Great job! Using relative paths to the files within your workflowr project makes it easier to run your code on other machines.</p>
</div>
</div>
</div>
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongRepositoryversionstrongahrefhttpsgithubcommarcsole96PIBworkflowrtree02a1d67d6692a3968a4a4964e7a29a83c39e2ff5targetblank02a1d67a"> <span class="glyphicon glyphicon-ok text-success" aria-hidden="true"></span> <strong>Repository version:</strong> <a href="https://github.com/marcsole96/PIB_workflowr/tree/02a1d67d6692a3968a4a4964e7a29a83c39e2ff5" target="_blank">02a1d67</a> </a>
</p>
</div>
<div id="strongRepositoryversionstrongahrefhttpsgithubcommarcsole96PIBworkflowrtree02a1d67d6692a3968a4a4964e7a29a83c39e2ff5targetblank02a1d67a" class="panel-collapse collapse">
<div class="panel-body">
<p>
Great! You are using Git for version control. Tracking code development and connecting the code version to the results is critical for reproducibility.
</p>
<p>
The results in this page were generated with repository version <a href="https://github.com/marcsole96/PIB_workflowr/tree/02a1d67d6692a3968a4a4964e7a29a83c39e2ff5" target="_blank">02a1d67</a>. See the <em>Past versions</em> tab to see a history of the changes made to the R Markdown and HTML files.
</p>
<p>
Note that you need to be careful to ensure that all relevant files for the analysis have been committed to Git prior to generating the results (you can use <code>wflow_publish</code> or <code>wflow_git_commit</code>). workflowr only checks the R Markdown file, but you know if there are other scripts or data files that it depends on. Below is the status of the Git repository when the results were generated:
</p>
<pre><code>
Ignored files:
    Ignored:    .Rhistory
    Ignored:    .Rproj.user/
    Ignored:    analysis/.Rhistory

Untracked files:
    Untracked:  data/CONTRACT REGION OF INTERESTED EXPORTS/
    Untracked:  data/INK SQUARE ANALYSIS (TRAINING SET)-roi EXPORTS/
    Untracked:  data/STRIKES ANALYSIS (I TEST SET)-ROI EXPORTS/

</code></pre>
<p>
Note that any generated files, e.g. HTML, png, CSS, etc., are not included in this status report because it is ok for generated content to have uncommitted changes.
</p>
</div>
</div>
</div>
</div>
<hr>
</div>
<div id="versions" class="tab-pane fade">

<p>
These are the previous versions of the repository in which changes were made to the R Markdown (<code>analysis/PiB.Rmd</code>) and HTML (<code>docs/PiB.html</code>) files. If you’ve configured a remote Git repository (see <code>?wflow_git_remote</code>), click on the hyperlinks in the table below to view the files as they were in that past version.
</p>
<div class="table-responsive">
<table class="table table-condensed table-hover">
<thead>
<tr>
<th>
File
</th>
<th>
Version
</th>
<th>
Author
</th>
<th>
Date
</th>
<th>
Message
</th>
</tr>
</thead>
<tbody>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/marcsole96/PIB_workflowr/blob/02a1d67d6692a3968a4a4964e7a29a83c39e2ff5/analysis/PiB.Rmd" target="_blank">02a1d67</a>
</td>
<td>
marcsole96
</td>
<td>
2021-10-12
</td>
<td>
hidden code, made plots of probability, made lasso
</td>
</tr>
<tr>
<td>
html
</td>
<td>
<a href="https://rawcdn.githack.com/marcsole96/PIB_workflowr/8a1e0b15e0194844831b340a8693d61cb586b594/docs/PiB.html" target="_blank">8a1e0b1</a>
</td>
<td>
marcsole96
</td>
<td>
2021-10-12
</td>
<td>
Build site.
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/marcsole96/PIB_workflowr/blob/83574fd1116c152a3c7c0a7c9a9f17b206e3a95d/analysis/PiB.Rmd" target="_blank">83574fd</a>
</td>
<td>
marcsole96
</td>
<td>
2021-10-12
</td>
<td>
hidden code, made plots of probability, made lasso
</td>
</tr>
<tr>
<td>
html
</td>
<td>
<a href="https://rawcdn.githack.com/marcsole96/PIB_workflowr/9a48040a7b66666fdbd8ec3e0c9d63c8773dd562/docs/PiB.html" target="_blank">9a48040</a>
</td>
<td>
marcsole96
</td>
<td>
2021-10-01
</td>
<td>
Build site.
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/marcsole96/PIB_workflowr/blob/2b6337bb15275c4467da88d53f5b56f44877b823/analysis/PiB.Rmd" target="_blank">2b6337b</a>
</td>
<td>
marcsole96
</td>
<td>
2021-10-01
</td>
<td>
caret model with whole train data
</td>
</tr>
<tr>
<td>
html
</td>
<td>
<a href="https://rawcdn.githack.com/marcsole96/PIB_workflowr/d84cd5e786b3da077158c37f40af18e7ff7996df/docs/PiB.html" target="_blank">d84cd5e</a>
</td>
<td>
marcsole96
</td>
<td>
2021-10-01
</td>
<td>
Build site.
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/marcsole96/PIB_workflowr/blob/002e6d3a04671405dea0a2f783b0e5b450ce5d0e/analysis/PiB.Rmd" target="_blank">002e6d3</a>
</td>
<td>
marcsole96
</td>
<td>
2021-10-01
</td>
<td>
caret model with whole train data
</td>
</tr>
<tr>
<td>
html
</td>
<td>
<a href="https://rawcdn.githack.com/marcsole96/PIB_workflowr/1f9abe4a88bc8c88beea20c8cbc7617f17596dd4/docs/PiB.html" target="_blank">1f9abe4</a>
</td>
<td>
marcsole96
</td>
<td>
2021-10-01
</td>
<td>
Build site.
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/marcsole96/PIB_workflowr/blob/58c6a8b5777ede490051114e013a741968a07651/analysis/PiB.Rmd" target="_blank">58c6a8b</a>
</td>
<td>
marcsole96
</td>
<td>
2021-10-01
</td>
<td>
caret model with whole train data
</td>
</tr>
<tr>
<td>
html
</td>
<td>
<a href="https://rawcdn.githack.com/marcsole96/PIB_workflowr/b08984e33218ad6e9eb2f3fd031134b8df9c9c07/docs/PiB.html" target="_blank">b08984e</a>
</td>
<td>
marcsole96
</td>
<td>
2021-09-29
</td>
<td>
wflow_git_commit(all = T)
</td>
</tr>
<tr>
<td>
html
</td>
<td>
<a href="https://rawcdn.githack.com/marcsole96/PIB_workflowr/2197b1412502ee893aef9390447becff144fae7e/docs/PiB.html" target="_blank">2197b14</a>
</td>
<td>
marcsole96
</td>
<td>
2021-09-29
</td>
<td>
Build site.
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/marcsole96/PIB_workflowr/blob/bcb4493b6c03026350322c5d21078065db3314a5/analysis/PiB.Rmd" target="_blank">bcb4493</a>
</td>
<td>
marcsole96
</td>
<td>
2021-09-29
</td>
<td>
comment
</td>
</tr>
<tr>
<td>
html
</td>
<td>
<a href="https://rawcdn.githack.com/marcsole96/PIB_workflowr/0e0b1bee0b2ca136686b6479c5fa6c994c4dcd0d/docs/PiB.html" target="_blank">0e0b1be</a>
</td>
<td>
marcsole96
</td>
<td>
2021-09-28
</td>
<td>
Build site.
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/marcsole96/PIB_workflowr/blob/3722b1422ba04e90e08e4196a35d44722fe3b353/analysis/PiB.Rmd" target="_blank">3722b14</a>
</td>
<td>
marcsole96
</td>
<td>
2021-09-28
</td>
<td>
changed dataframes labels
</td>
</tr>
<tr>
<td>
html
</td>
<td>
<a href="https://rawcdn.githack.com/marcsole96/PIB_workflowr/35602fa41a9c7d01bb8fe297cc6bc8483e3b0418/docs/PiB.html" target="_blank">35602fa</a>
</td>
<td>
marcsole96
</td>
<td>
2021-09-27
</td>
<td>
Build site.
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/marcsole96/PIB_workflowr/blob/c29bb1c7041774dcb5f6d8bde3d310c6657b6924/analysis/PiB.Rmd" target="_blank">c29bb1c</a>
</td>
<td>
marcsole96
</td>
<td>
2021-09-27
</td>
<td>
changed labels
</td>
</tr>
<tr>
<td>
html
</td>
<td>
<a href="https://rawcdn.githack.com/marcsole96/PIB_workflowr/e38b246103c9af9766457f93e107b655e6fa0d69/docs/PiB.html" target="_blank">e38b246</a>
</td>
<td>
marcsole96
</td>
<td>
2021-09-24
</td>
<td>
Build site.
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/marcsole96/PIB_workflowr/blob/edea607233fbc2f315a547f3aac063ca5b351166/analysis/PiB.Rmd" target="_blank">edea607</a>
</td>
<td>
marcsole96
</td>
<td>
2021-09-24
</td>
<td>
wflow_publish("../analysis/*")
</td>
</tr>
<tr>
<td>
html
</td>
<td>
<a href="https://rawcdn.githack.com/marcsole96/PIB_workflowr/5991c0d0af28f48edeed739ede8c16c803f81571/docs/PiB.html" target="_blank">5991c0d</a>
</td>
<td>
marcsole96
</td>
<td>
2021-09-24
</td>
<td>
Build site.
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/marcsole96/PIB_workflowr/blob/687bb6cf0b38bb4285e062eba10e64221d7e79c2/analysis/PiB.Rmd" target="_blank">687bb6c</a>
</td>
<td>
marcsole96
</td>
<td>
2021-09-24
</td>
<td>
tried caret for pca model
</td>
</tr>
<tr>
<td>
html
</td>
<td>
<a href="https://rawcdn.githack.com/marcsole96/PIB_workflowr/ff358022fe4d91155b8bb273cecc766ffd0197c1/docs/PiB.html" target="_blank">ff35802</a>
</td>
<td>
marcsole96
</td>
<td>
2021-09-23
</td>
<td>
Build site.
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/marcsole96/PIB_workflowr/blob/e39c13dc4c9e35f156256bf8ee2d4917e811bbd4/analysis/PiB.Rmd" target="_blank">e39c13d</a>
</td>
<td>
marcsole96
</td>
<td>
2021-09-23
</td>
<td>
clened things
</td>
</tr>
<tr>
<td>
html
</td>
<td>
<a href="https://rawcdn.githack.com/marcsole96/PIB_workflowr/91d3e038ee657ca6c1a13375b382f2177aaef0da/docs/PiB.html" target="_blank">91d3e03</a>
</td>
<td>
marcsole96
</td>
<td>
2021-09-16
</td>
<td>
Build site.
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/marcsole96/PIB_workflowr/blob/a532404bae91336e930f5e83daf0ac780f94e730/analysis/PiB.Rmd" target="_blank">a532404</a>
</td>
<td>
marcsole96
</td>
<td>
2021-09-16
</td>
<td>
Added the first attempt to do a pca classification model
</td>
</tr>
<tr>
<td>
html
</td>
<td>
<a href="https://rawcdn.githack.com/marcsole96/PIB_workflowr/91742f40916d69242e461e8e8273bbfb1f9db316/docs/PiB.html" target="_blank">91742f4</a>
</td>
<td>
marcsole96
</td>
<td>
2021-09-14
</td>
<td>
Build site.
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/marcsole96/PIB_workflowr/blob/2b0be5d423e17994fda90e0693cb8fe8da65d789/analysis/PiB.Rmd" target="_blank">2b0be5d</a>
</td>
<td>
marcsole96
</td>
<td>
2021-09-14
</td>
<td>
made a PCA for all the training data
</td>
</tr>
<tr>
<td>
html
</td>
<td>
<a href="https://rawcdn.githack.com/marcsole96/PIB_workflowr/691fdc359e4943d088c37a036ba77c04c97490a2/docs/PiB.html" target="_blank">691fdc3</a>
</td>
<td>
marcsole96
</td>
<td>
2021-09-14
</td>
<td>
Build site.
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/marcsole96/PIB_workflowr/blob/c93712f8dae91d40b2d5d5b2dc26a4875303c3f3/analysis/PiB.Rmd" target="_blank">c93712f</a>
</td>
<td>
marcsole96
</td>
<td>
2021-09-14
</td>
<td>
made a PCA for all the training data
</td>
</tr>
<tr>
<td>
html
</td>
<td>
<a href="https://rawcdn.githack.com/marcsole96/PIB_workflowr/bdb8f53b9c8024790c4abbd47c91335955483142/docs/PiB.html" target="_blank">bdb8f53</a>
</td>
<td>
marcsole96
</td>
<td>
2021-09-14
</td>
<td>
Build site.
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/marcsole96/PIB_workflowr/blob/d642a4877d2baa435269ec85e98ae46891c78f8a/analysis/PiB.Rmd" target="_blank">d642a48</a>
</td>
<td>
marcsole96
</td>
<td>
2021-09-14
</td>
<td>
made a PCA for all the training data
</td>
</tr>
<tr>
<td>
html
</td>
<td>
<a href="https://rawcdn.githack.com/marcsole96/PIB_workflowr/74d75599ff020650bca86525309f97093fa63fb8/docs/PiB.html" target="_blank">74d7559</a>
</td>
<td>
marcsole96
</td>
<td>
2021-09-14
</td>
<td>
Build site.
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/marcsole96/PIB_workflowr/blob/c4c4781c771c45b0616e115fced56a9e4546a949/analysis/PiB.Rmd" target="_blank">c4c4781</a>
</td>
<td>
marcsole96
</td>
<td>
2021-09-14
</td>
<td>
Made a merged DF with all the training data
</td>
</tr>
<tr>
<td>
html
</td>
<td>
<a href="https://rawcdn.githack.com/marcsole96/PIB_workflowr/f9368cb09a9cc5e8b024ae9255d422da7e9bc22a/docs/PiB.html" target="_blank">f9368cb</a>
</td>
<td>
marcsole96
</td>
<td>
2021-09-14
</td>
<td>
Build site.
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/marcsole96/PIB_workflowr/blob/9d0c7d42352d882878a9ede57e20c8175d7f4535/analysis/PiB.Rmd" target="_blank">9d0c7d4</a>
</td>
<td>
marcsole96
</td>
<td>
2021-09-14
</td>
<td>
Created a merged DF with all the training data
</td>
</tr>
<tr>
<td>
html
</td>
<td>
<a href="https://rawcdn.githack.com/marcsole96/PIB_workflowr/aa4744316fdb93153ad61eb94d75f01bbd311db3/docs/PiB.html" target="_blank">aa47443</a>
</td>
<td>
marcsole96
</td>
<td>
2021-09-14
</td>
<td>
Build site.
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/marcsole96/PIB_workflowr/blob/46897a7dbc0d89fca119d44697c06b5a6f29c1aa/analysis/PiB.Rmd" target="_blank">46897a7</a>
</td>
<td>
marcsole96
</td>
<td>
2021-09-14
</td>
<td>
Created a merged DF with all the training data
</td>
</tr>
<tr>
<td>
html
</td>
<td>
<a href="https://rawcdn.githack.com/marcsole96/PIB_workflowr/1404a14167bbc4e804f0b0ffb77d5b5d349dba3b/docs/PiB.html" target="_blank">1404a14</a>
</td>
<td>
marcsole96
</td>
<td>
2021-09-13
</td>
<td>
Build site.
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/marcsole96/PIB_workflowr/blob/39a620e120634a199dcf9dabb47112789df06928/analysis/PiB.Rmd" target="_blank">39a620e</a>
</td>
<td>
marcsole96
</td>
<td>
2021-09-13
</td>
<td>
wflow_publish(“../analysis/PiB.Rmd”)
</td>
</tr>
<tr>
<td>
html
</td>
<td>
<a href="https://rawcdn.githack.com/marcsole96/PIB_workflowr/e44ec66fb5d5c0bcf7fb85251ec553002dc84ec6/docs/PiB.html" target="_blank">e44ec66</a>
</td>
<td>
marcsole96
</td>
<td>
2021-09-13
</td>
<td>
Build site.
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/marcsole96/PIB_workflowr/blob/7df0598abcde87f96bbe47dae0b47e241056f284/analysis/PiB.Rmd" target="_blank">7df0598</a>
</td>
<td>
marcsole96
</td>
<td>
2021-09-13
</td>
<td>
wflow_publish(c("../_workflowr.yml“,”../analysis/PiB.Rmd"))
</td>
</tr>
<tr>
<td>
html
</td>
<td>
<a href="https://rawcdn.githack.com/marcsole96/PIB_workflowr/a26decb9568a05c7d06c2bf0c236044e11cdd7ee/docs/PiB.html" target="_blank">a26decb</a>
</td>
<td>
marcsole96
</td>
<td>
2021-09-12
</td>
<td>
wflow_publish(“../analysis/index.Rmd”)
</td>
</tr>
<tr>
<td>
html
</td>
<td>
<a href="https://rawcdn.githack.com/marcsole96/PIB_workflowr/5b3175d7f65afd4786abfd19b68d2cf152ad0eea/docs/PiB.html" target="_blank">5b3175d</a>
</td>
<td>
marcsole96
</td>
<td>
2021-09-12
</td>
<td>
Build site.
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/marcsole96/PIB_workflowr/blob/158e2227af48d94b68a0d70c52ba1f62a4200a20/analysis/PiB.Rmd" target="_blank">158e222</a>
</td>
<td>
marcsole96
</td>
<td>
2021-09-12
</td>
<td>
wflow_publish(“../analysis/PiB.Rmd”)
</td>
</tr>
<tr>
<td>
html
</td>
<td>
<a href="https://rawcdn.githack.com/marcsole96/PIB_workflowr/125ff6ea060a7c4fdd7082d18dc0362aebef439f/docs/PiB.html" target="_blank">125ff6e</a>
</td>
<td>
marcsole96
</td>
<td>
2021-09-10
</td>
<td>
Build site.
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/marcsole96/PIB_workflowr/blob/b2c214032e8841813f6e54a6afdcce12bdc6a267/analysis/PiB.Rmd" target="_blank">b2c2140</a>
</td>
<td>
marcsole96
</td>
<td>
2021-09-10
</td>
<td>
wflow_publish(“../analysis/PiB.Rmd”)
</td>
</tr>
</tbody>
</table>
</div>
<hr>
</div>
</div>
</div>
<div id="setup" class="section level1">
<h1>Setup</h1>
</div>
<div id="contract-region-of-interested-exports" class="section level1">
<h1>CONTRACT REGION OF INTERESTED EXPORTS</h1>
<div id="page-1-contract-exports" class="section level2">
<h2>Page 1 contract exports</h2>
</div>
<div id="page-2-contract-exports" class="section level2">
<h2>Page 2 contract exports</h2>
</div>
<div id="page-3-contract-export" class="section level2">
<h2>Page 3 contract export</h2>
</div>
</div>
<div id="ink-square-analysis-training-set-roi-exports" class="section level1">
<h1>INK SQUARE ANALYSIS (TRAINING SET)-roi EXPORTS</h1>
<div id="full-squares" class="section level2">
<h2>full squares</h2>
</div>
<div id="numbers" class="section level2">
<h2>numbers</h2>
</div>
<div id="split-squares_each-square-3-roi" class="section level2">
<h2>split squares_each square 3 ROI</h2>
</div>
</div>
<div id="strikes-analysis-i-test-set-roi-exports" class="section level1">
<h1>STRIKES ANALYSIS (I TEST SET)-ROI EXPORTS</h1>
</div>
<div id="datasets-compilation" class="section level1">
<h1>Datasets compilation</h1>
<p>#Simple intensities plots:</p>
<p>Testdata</p>
<p>Training data 1</p>
<p>Training data 2</p>
<p>Training data 2</p>
</div>
<div id="pcas" class="section level1">
<h1>PCAs</h1>
<div id="test_data" class="section level2">
<h2>Test_data</h2>
</div>
<div id="test-by-transposing-the-data" class="section level2">
<h2>Test by transposing the data</h2>
</div>
<div id="test-by-not-transposing-the-data" class="section level2">
<h2>Test by NOT transposing the data</h2>
<p>Changing the columns so they are rows:</p>
</div>
<div id="training_data1" class="section level2">
<h2>training_data1</h2>
<p>Changing the columns so they are rows:</p>
</div>
<div id="training_data2" class="section level2">
<h2>training_data2</h2>
<p>Changing the columns so they are rows:</p>
</div>
<div id="training_data3" class="section level2">
<h2>training_data3</h2>
<p>Changing the columns so they are rows:</p>
<p>#tSNE ## Test_data</p>
</div>
<div id="train-data-1" class="section level2">
<h2>Train data 1</h2>
</div>
<div id="train-data-2" class="section level2">
<h2>Train data 2</h2>
</div>
<div id="train-data-3" class="section level2">
<h2>Train data 3</h2>
</div>
</div>
<div id="merge-train_data-on-a-single-df" class="section level1">
<h1>Merge train_data on a single DF:</h1>
<p>We have 3 DFs containging training_data</p>
<p>Each of them (despite having different regions analyzed) contain information on the squares which in turn can be used to identify the type of pen used.</p>
<p>Merging</p>
<p>We could now simplify the DF by simply stating which square is which</p>
</div>
<div id="pca-of-training-data" class="section level1">
<h1>PCA of training data</h1>
<p>Now we could do a PCA from the whole data</p>
<p>We can see the variance explained by the PCs:</p>
<p>We can view the 3 PCs:</p>
</div>
<div id="model-from-pca-training-data" class="section level1">
<h1>Model from PCA training Data:</h1>
<p>I used this as a guide: <a href="https://rstudio-pubs-static.s3.amazonaws.com/285614_7921f4f9f340428f8f5ed8dc3c7f7943.html" class="uri">https://rstudio-pubs-static.s3.amazonaws.com/285614_7921f4f9f340428f8f5ed8dc3c7f7943.html</a></p>
<pre class="r"><code>#For the test data we should use the test_data
#For the training data we should use the training_DF

#(work in progress, I have to remember how this was done :/ )

#Get a dataframe with the values that will be used to predict
#First step, transpose the data: 
t_test_data&lt;-as.data.frame(t(test_data[-1]))
names(t_test_data)&lt;-test_data$spectrum
t_test_data$labels=row.names(t_test_data)
#removing the row headers
rownames(t_test_data)&lt;-c()
#moving labels to the beginning
t_test_data&lt;-t_test_data %&gt;% 
  select(labels, everything())
t_test_data&lt;-t_test_data %&gt;% replace(1,c(&quot;strike1&quot;,&quot;strike2&quot;,&quot;strike3&quot;,&quot;strike4&quot;,&quot;strike5&quot;,&quot;strike6&quot;))
head(select(t_test_data,1:5))</code></pre>
<pre><code>   labels      100    100.2    100.4    100.6
1 strike1 1.220990 1.243090 1.176800 0.955801
2 strike2 1.804470 2.251400 1.810060 1.703910
3 strike3 0.572254 0.953757 0.849711 0.699422
4 strike4 0.722826 0.956522 0.880435 0.728261
5 strike5 0.500000 0.540816 0.607143 0.612245
6 strike6 0.294737 0.652632 0.436842 0.368421</code></pre>
<pre class="r"><code>test&lt;-t_test_data[-1]


library(caret)
library(e1071)
pca = preProcess(x = training_DF[,c(-1,-4502)], method = &quot;pca&quot;, pcaComp = 35)
training_set &lt;- predict(pca, training_DF[-4502])
# put customer segment in to the last postion or column
#training_set &lt;- simple_train_DF[c(2,3,1)]


test_set &lt;- predict(pca, test)
#test_set &lt;- test[c(2,3,1)]

trControl &lt;- trainControl(method = &quot;repeatedcv&quot;, 
                          number = 10, 
                         repeats = 3, 
                     verboseIter = ifelse(is.null(getOption(&#39;knitr.in.progress&#39;)), TRUE, FALSE) # This crazy line is to show progress when you run the code but hide it when knitting.
    )

training_x &lt;- training_set %&gt;% select(-labels) %&gt;% as.data.frame()
training_y &lt;- training_set$labels

car_ranger &lt;- train(x = training_x, 
             y = training_y, 
        method = &quot;glmnet&quot;,
     trControl = trControl
    )

print(car_ranger)</code></pre>
<pre><code>glmnet 

35 samples
35 predictors
 6 classes: &#39;pen1&#39;, &#39;pen2&#39;, &#39;pen3&#39;, &#39;pen4&#39;, &#39;pen5&#39;, &#39;pen6&#39; 

No pre-processing
Resampling: Cross-Validated (10 fold, repeated 3 times) 
Summary of sample sizes: 32, 34, 32, 32, 31, 31, ... 
Resampling results across tuning parameters:

  alpha  lambda        Accuracy   Kappa    
  0.10   0.0004928533  0.3627778  0.1996062
  0.10   0.0049285332  0.3627778  0.1996062
  0.10   0.0492853324  0.3850000  0.2257967
  0.55   0.0004928533  0.6883333  0.5959391
  0.55   0.0049285332  0.6950000  0.6045598
  0.55   0.0492853324  0.7144444  0.6341165
  1.00   0.0004928533  0.6988889  0.6126437
  1.00   0.0049285332  0.6988889  0.6144120
  1.00   0.0492853324  0.7861111  0.7108185

Accuracy was used to select the optimal model using the largest value.
The final values used for the model were alpha = 1 and lambda = 0.04928533.</code></pre>
<pre class="r"><code>predicted&lt;- predict(car_ranger, newdata = test_set[,-1])

predicted</code></pre>
<pre><code>[1] pen4 pen2 pen3 pen4 pen5 pen6
Levels: pen1 pen2 pen3 pen4 pen5 pen6</code></pre>
<pre class="r"><code>#Cleanup
rm(car_ranger,dat_3d,data,fig,lowd_map,pca,pca_res,pr.out, t_training_data1, t_training_data2, t_training_data3, test, test_pca, test_set, training_data1, training_data2, training_data3,training_set, training_x,trControl,tsne, avector, labels, names, predicted, training_y,var_explained)</code></pre>
</div>
<div id="caret-model-not-using-pcas" class="section level1">
<h1>Caret model not using PCAs</h1>
<div id="preparing-the-test_data" class="section level2">
<h2>Preparing the test_data</h2>
<pre class="r"><code>#For the test data we should use the test_data
#For the training data we should use the training_DF

#(work in progress, I have to remember how this was done :/ )

#Get a dataframe with the values that will be used to predict
#First step, transpose the data: 
t_test_data&lt;-as.data.frame(t(test_data[-1]))
names(t_test_data)&lt;-test_data$spectrum
t_test_data$labels=row.names(t_test_data)
#removing the row headers
rownames(t_test_data)&lt;-c()
#moving labels to the beginning
t_test_data&lt;-t_test_data %&gt;% 
  select(labels, everything())
t_test_data&lt;-t_test_data %&gt;% replace(1,c(&quot;strike1&quot;,&quot;strike2&quot;,&quot;strike3&quot;,&quot;strike4&quot;,&quot;strike5&quot;,&quot;strike6&quot;))
head(select(t_test_data,1:5))</code></pre>
<pre><code>   labels      100    100.2    100.4    100.6
1 strike1 1.220990 1.243090 1.176800 0.955801
2 strike2 1.804470 2.251400 1.810060 1.703910
3 strike3 0.572254 0.953757 0.849711 0.699422
4 strike4 0.722826 0.956522 0.880435 0.728261
5 strike5 0.500000 0.540816 0.607143 0.612245
6 strike6 0.294737 0.652632 0.436842 0.368421</code></pre>
<pre class="r"><code>test_data&lt;-t_test_data

rm(t_test_data)</code></pre>
<p>##Caret model GLMNET</p>
<pre class="r"><code>training_x &lt;- training_DF %&gt;% select(-labels) %&gt;% as.data.frame()
training_y &lt;- training_DF$labels

trControl &lt;- trainControl(method = &quot;repeatedcv&quot;, number = 5, repeats = 3, verboseIter = T)

fit &lt;- train(x = training_x, 
             y = training_y, 
        method = &quot;glmnet&quot;,
        tuneLength = 5,
     trControl = trControl
    )</code></pre>
<pre><code>+ Fold1.Rep1: alpha=0.100, lambda=0.3244 
- Fold1.Rep1: alpha=0.100, lambda=0.3244 
+ Fold1.Rep1: alpha=0.325, lambda=0.3244 
- Fold1.Rep1: alpha=0.325, lambda=0.3244 
+ Fold1.Rep1: alpha=0.550, lambda=0.3244 
- Fold1.Rep1: alpha=0.550, lambda=0.3244 
+ Fold1.Rep1: alpha=0.775, lambda=0.3244 
- Fold1.Rep1: alpha=0.775, lambda=0.3244 
+ Fold1.Rep1: alpha=1.000, lambda=0.3244 
- Fold1.Rep1: alpha=1.000, lambda=0.3244 
+ Fold2.Rep1: alpha=0.100, lambda=0.3244 
- Fold2.Rep1: alpha=0.100, lambda=0.3244 
+ Fold2.Rep1: alpha=0.325, lambda=0.3244 
- Fold2.Rep1: alpha=0.325, lambda=0.3244 
+ Fold2.Rep1: alpha=0.550, lambda=0.3244 
- Fold2.Rep1: alpha=0.550, lambda=0.3244 
+ Fold2.Rep1: alpha=0.775, lambda=0.3244 
- Fold2.Rep1: alpha=0.775, lambda=0.3244 
+ Fold2.Rep1: alpha=1.000, lambda=0.3244 
- Fold2.Rep1: alpha=1.000, lambda=0.3244 
+ Fold3.Rep1: alpha=0.100, lambda=0.3244 
- Fold3.Rep1: alpha=0.100, lambda=0.3244 
+ Fold3.Rep1: alpha=0.325, lambda=0.3244 
- Fold3.Rep1: alpha=0.325, lambda=0.3244 
+ Fold3.Rep1: alpha=0.550, lambda=0.3244 
- Fold3.Rep1: alpha=0.550, lambda=0.3244 
+ Fold3.Rep1: alpha=0.775, lambda=0.3244 
- Fold3.Rep1: alpha=0.775, lambda=0.3244 
+ Fold3.Rep1: alpha=1.000, lambda=0.3244 
- Fold3.Rep1: alpha=1.000, lambda=0.3244 
+ Fold4.Rep1: alpha=0.100, lambda=0.3244 
- Fold4.Rep1: alpha=0.100, lambda=0.3244 
+ Fold4.Rep1: alpha=0.325, lambda=0.3244 
- Fold4.Rep1: alpha=0.325, lambda=0.3244 
+ Fold4.Rep1: alpha=0.550, lambda=0.3244 
- Fold4.Rep1: alpha=0.550, lambda=0.3244 
+ Fold4.Rep1: alpha=0.775, lambda=0.3244 
- Fold4.Rep1: alpha=0.775, lambda=0.3244 
+ Fold4.Rep1: alpha=1.000, lambda=0.3244 
- Fold4.Rep1: alpha=1.000, lambda=0.3244 
+ Fold5.Rep1: alpha=0.100, lambda=0.3244 
- Fold5.Rep1: alpha=0.100, lambda=0.3244 
+ Fold5.Rep1: alpha=0.325, lambda=0.3244 
- Fold5.Rep1: alpha=0.325, lambda=0.3244 
+ Fold5.Rep1: alpha=0.550, lambda=0.3244 
- Fold5.Rep1: alpha=0.550, lambda=0.3244 
+ Fold5.Rep1: alpha=0.775, lambda=0.3244 
- Fold5.Rep1: alpha=0.775, lambda=0.3244 
+ Fold5.Rep1: alpha=1.000, lambda=0.3244 
- Fold5.Rep1: alpha=1.000, lambda=0.3244 
+ Fold1.Rep2: alpha=0.100, lambda=0.3244 
- Fold1.Rep2: alpha=0.100, lambda=0.3244 
+ Fold1.Rep2: alpha=0.325, lambda=0.3244 
- Fold1.Rep2: alpha=0.325, lambda=0.3244 
+ Fold1.Rep2: alpha=0.550, lambda=0.3244 
- Fold1.Rep2: alpha=0.550, lambda=0.3244 
+ Fold1.Rep2: alpha=0.775, lambda=0.3244 
- Fold1.Rep2: alpha=0.775, lambda=0.3244 
+ Fold1.Rep2: alpha=1.000, lambda=0.3244 
- Fold1.Rep2: alpha=1.000, lambda=0.3244 
+ Fold2.Rep2: alpha=0.100, lambda=0.3244 
- Fold2.Rep2: alpha=0.100, lambda=0.3244 
+ Fold2.Rep2: alpha=0.325, lambda=0.3244 
- Fold2.Rep2: alpha=0.325, lambda=0.3244 
+ Fold2.Rep2: alpha=0.550, lambda=0.3244 
- Fold2.Rep2: alpha=0.550, lambda=0.3244 
+ Fold2.Rep2: alpha=0.775, lambda=0.3244 
- Fold2.Rep2: alpha=0.775, lambda=0.3244 
+ Fold2.Rep2: alpha=1.000, lambda=0.3244 
- Fold2.Rep2: alpha=1.000, lambda=0.3244 
+ Fold3.Rep2: alpha=0.100, lambda=0.3244 
- Fold3.Rep2: alpha=0.100, lambda=0.3244 
+ Fold3.Rep2: alpha=0.325, lambda=0.3244 
- Fold3.Rep2: alpha=0.325, lambda=0.3244 
+ Fold3.Rep2: alpha=0.550, lambda=0.3244 
- Fold3.Rep2: alpha=0.550, lambda=0.3244 
+ Fold3.Rep2: alpha=0.775, lambda=0.3244 
- Fold3.Rep2: alpha=0.775, lambda=0.3244 
+ Fold3.Rep2: alpha=1.000, lambda=0.3244 
- Fold3.Rep2: alpha=1.000, lambda=0.3244 
+ Fold4.Rep2: alpha=0.100, lambda=0.3244 
- Fold4.Rep2: alpha=0.100, lambda=0.3244 
+ Fold4.Rep2: alpha=0.325, lambda=0.3244 
- Fold4.Rep2: alpha=0.325, lambda=0.3244 
+ Fold4.Rep2: alpha=0.550, lambda=0.3244 
- Fold4.Rep2: alpha=0.550, lambda=0.3244 
+ Fold4.Rep2: alpha=0.775, lambda=0.3244 
- Fold4.Rep2: alpha=0.775, lambda=0.3244 
+ Fold4.Rep2: alpha=1.000, lambda=0.3244 
- Fold4.Rep2: alpha=1.000, lambda=0.3244 
+ Fold5.Rep2: alpha=0.100, lambda=0.3244 
- Fold5.Rep2: alpha=0.100, lambda=0.3244 
+ Fold5.Rep2: alpha=0.325, lambda=0.3244 
- Fold5.Rep2: alpha=0.325, lambda=0.3244 
+ Fold5.Rep2: alpha=0.550, lambda=0.3244 
- Fold5.Rep2: alpha=0.550, lambda=0.3244 
+ Fold5.Rep2: alpha=0.775, lambda=0.3244 
- Fold5.Rep2: alpha=0.775, lambda=0.3244 
+ Fold5.Rep2: alpha=1.000, lambda=0.3244 
- Fold5.Rep2: alpha=1.000, lambda=0.3244 
+ Fold1.Rep3: alpha=0.100, lambda=0.3244 
- Fold1.Rep3: alpha=0.100, lambda=0.3244 
+ Fold1.Rep3: alpha=0.325, lambda=0.3244 
- Fold1.Rep3: alpha=0.325, lambda=0.3244 
+ Fold1.Rep3: alpha=0.550, lambda=0.3244 
- Fold1.Rep3: alpha=0.550, lambda=0.3244 
+ Fold1.Rep3: alpha=0.775, lambda=0.3244 
- Fold1.Rep3: alpha=0.775, lambda=0.3244 
+ Fold1.Rep3: alpha=1.000, lambda=0.3244 
- Fold1.Rep3: alpha=1.000, lambda=0.3244 
+ Fold2.Rep3: alpha=0.100, lambda=0.3244 
- Fold2.Rep3: alpha=0.100, lambda=0.3244 
+ Fold2.Rep3: alpha=0.325, lambda=0.3244 
- Fold2.Rep3: alpha=0.325, lambda=0.3244 
+ Fold2.Rep3: alpha=0.550, lambda=0.3244 
- Fold2.Rep3: alpha=0.550, lambda=0.3244 
+ Fold2.Rep3: alpha=0.775, lambda=0.3244 
- Fold2.Rep3: alpha=0.775, lambda=0.3244 
+ Fold2.Rep3: alpha=1.000, lambda=0.3244 
- Fold2.Rep3: alpha=1.000, lambda=0.3244 
+ Fold3.Rep3: alpha=0.100, lambda=0.3244 
- Fold3.Rep3: alpha=0.100, lambda=0.3244 
+ Fold3.Rep3: alpha=0.325, lambda=0.3244 
- Fold3.Rep3: alpha=0.325, lambda=0.3244 
+ Fold3.Rep3: alpha=0.550, lambda=0.3244 
- Fold3.Rep3: alpha=0.550, lambda=0.3244 
+ Fold3.Rep3: alpha=0.775, lambda=0.3244 
- Fold3.Rep3: alpha=0.775, lambda=0.3244 
+ Fold3.Rep3: alpha=1.000, lambda=0.3244 
- Fold3.Rep3: alpha=1.000, lambda=0.3244 
+ Fold4.Rep3: alpha=0.100, lambda=0.3244 
- Fold4.Rep3: alpha=0.100, lambda=0.3244 
+ Fold4.Rep3: alpha=0.325, lambda=0.3244 
- Fold4.Rep3: alpha=0.325, lambda=0.3244 
+ Fold4.Rep3: alpha=0.550, lambda=0.3244 
- Fold4.Rep3: alpha=0.550, lambda=0.3244 
+ Fold4.Rep3: alpha=0.775, lambda=0.3244 
- Fold4.Rep3: alpha=0.775, lambda=0.3244 
+ Fold4.Rep3: alpha=1.000, lambda=0.3244 
- Fold4.Rep3: alpha=1.000, lambda=0.3244 
+ Fold5.Rep3: alpha=0.100, lambda=0.3244 
- Fold5.Rep3: alpha=0.100, lambda=0.3244 
+ Fold5.Rep3: alpha=0.325, lambda=0.3244 
- Fold5.Rep3: alpha=0.325, lambda=0.3244 
+ Fold5.Rep3: alpha=0.550, lambda=0.3244 
- Fold5.Rep3: alpha=0.550, lambda=0.3244 
+ Fold5.Rep3: alpha=0.775, lambda=0.3244 
- Fold5.Rep3: alpha=0.775, lambda=0.3244 
+ Fold5.Rep3: alpha=1.000, lambda=0.3244 
- Fold5.Rep3: alpha=1.000, lambda=0.3244 
Aggregating results
Selecting tuning parameters
Fitting alpha = 0.1, lambda = 0.151 on full training set</code></pre>
<pre class="r"><code>print(fit)</code></pre>
<pre><code>glmnet 

  35 samples
4501 predictors
   6 classes: &#39;pen1&#39;, &#39;pen2&#39;, &#39;pen3&#39;, &#39;pen4&#39;, &#39;pen5&#39;, &#39;pen6&#39; 

No pre-processing
Resampling: Cross-Validated (5 fold, repeated 3 times) 
Summary of sample sizes: 28, 29, 27, 28, 28, 29, ... 
Resampling results across tuning parameters:

  alpha  lambda      Accuracy   Kappa     
  0.100  0.01505603  0.9123016  0.89177471
  0.100  0.03243724  0.9123016  0.89177471
  0.100  0.06988391  0.9123016  0.89177471
  0.100  0.15056033  0.9123016  0.89177471
  0.100  0.32437241  0.9027778  0.87886423
  0.325  0.01505603  0.9123016  0.89177471
  0.325  0.03243724  0.9027778  0.87886423
  0.325  0.06988391  0.8932540  0.86719757
  0.325  0.15056033  0.8932540  0.86719757
  0.325  0.32437241  0.8658730  0.83387489
  0.550  0.01505603  0.8837302  0.85677471
  0.550  0.03243724  0.8742063  0.84386423
  0.550  0.06988391  0.8753968  0.84708452
  0.550  0.15056033  0.8658730  0.83387489
  0.550  0.32437241  0.8146825  0.76979482
  0.775  0.01505603  0.8742063  0.84386423
  0.775  0.03243724  0.8753968  0.84708452
  0.775  0.06988391  0.8753968  0.84708452
  0.775  0.15056033  0.8658730  0.83387489
  0.775  0.32437241  0.7503968  0.68585034
  1.000  0.01505603  0.8742063  0.84386423
  1.000  0.03243724  0.8753968  0.84708452
  1.000  0.06988391  0.8658730  0.83417404
  1.000  0.15056033  0.8480159  0.81102289
  1.000  0.32437241  0.2738095  0.02962963

Accuracy was used to select the optimal model using the largest value.
The final values used for the model were alpha = 0.1 and lambda = 0.1505603.</code></pre>
<pre class="r"><code>ggplot(fit)</code></pre>
<p><img src="figure/PiB.Rmd/unnamed-chunk-41-1.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code>predicted&lt;- predict(fit, newdata = test_data[,-1],type = &quot;prob&quot;)</code></pre>
<div id="plots" class="section level3">
<h3>Plots</h3>
<pre class="r"><code>toplot&lt;-as.data.frame(t(predicted))
names(toplot)&lt;-c(&quot;strike1&quot;,&quot;strike2&quot;,&quot;strike3&quot;,&quot;strike4&quot;,&quot;strike5&quot;,&quot;strike6&quot;)
toplot&lt;-toplot %&gt;% mutate(pens=row.names(toplot))

strike1&lt;-toplot %&gt;% select(strike1,pens) %&gt;% ggplot(aes(x=pens, y=strike1, fill=pens)) +
  geom_bar(stat=&quot;identity&quot;,position=position_stack())+
  scale_fill_brewer(palette=&quot;Accent&quot;)

strike2&lt;-toplot %&gt;% select(strike2,pens) %&gt;% ggplot(aes(x=pens, y=strike2, fill=pens)) +
  geom_bar(stat=&quot;identity&quot;,position=position_stack())+
  scale_fill_brewer(palette=&quot;Accent&quot;)

strike3&lt;-toplot %&gt;% select(strike3,pens) %&gt;% ggplot(aes(x=pens, y=strike3, fill=pens)) +
  geom_bar(stat=&quot;identity&quot;,position=position_stack())+
  scale_fill_brewer(palette=&quot;Accent&quot;)

strike4&lt;-toplot %&gt;% select(strike4,pens) %&gt;% ggplot(aes(x=pens, y=strike4, fill=pens)) +
  geom_bar(stat=&quot;identity&quot;,position=position_stack())+
  scale_fill_brewer(palette=&quot;Accent&quot;)

strike5&lt;-toplot %&gt;% select(strike5,pens) %&gt;% ggplot(aes(x=pens, y=strike5, fill=pens)) +
  geom_bar(stat=&quot;identity&quot;,position=position_stack())+
  scale_fill_brewer(palette=&quot;Accent&quot;)

strike6&lt;-toplot %&gt;% select(strike6,pens) %&gt;% ggplot(aes(x=pens, y=strike6, fill=pens)) +
  geom_bar(stat=&quot;identity&quot;,position=position_stack())+
  scale_fill_brewer(palette=&quot;Accent&quot;)


ggarrange(strike1, strike2, strike3, strike4, strike5, strike6,
                    labels = c(&quot;strike1&quot;, &quot;strike2&quot;, &quot;strike3&quot;, &quot;strike4&quot;, &quot;strike5&quot;, &quot;strike6&quot;),
                    ncol = 3, nrow = 3)</code></pre>
<p><img src="figure/PiB.Rmd/unnamed-chunk-42-1.png" width="960" style="display: block; margin: auto;" /></p>
<p>##Caret model GLMNET Lasso (Alpha = 1) Lambda ranging from 0 to 1</p>
<pre class="r"><code>training_x &lt;- training_DF %&gt;% select(-labels) %&gt;% as.data.frame()
training_y &lt;- training_DF$labels

trControl &lt;- trainControl(method = &quot;LOOCV&quot;, number = 5, verboseIter = T)


tuneGrid &lt;- expand.grid(alpha = 1, lambda = seq(0.001, 1, length = 1000))

fit &lt;- train(x = training_x, 
             y = training_y, 
        method = &quot;glmnet&quot;,
        tuneGrid = tuneGrid,
     trControl = trControl,
    )</code></pre>
<pre><code>+ Fold01: alpha=1, lambda=1 
- Fold01: alpha=1, lambda=1 
+ Fold02: alpha=1, lambda=1 
- Fold02: alpha=1, lambda=1 
+ Fold03: alpha=1, lambda=1 
- Fold03: alpha=1, lambda=1 
+ Fold04: alpha=1, lambda=1 
- Fold04: alpha=1, lambda=1 
+ Fold05: alpha=1, lambda=1 
- Fold05: alpha=1, lambda=1 
+ Fold06: alpha=1, lambda=1 
- Fold06: alpha=1, lambda=1 
+ Fold07: alpha=1, lambda=1 
- Fold07: alpha=1, lambda=1 
+ Fold08: alpha=1, lambda=1 
- Fold08: alpha=1, lambda=1 
+ Fold09: alpha=1, lambda=1 
- Fold09: alpha=1, lambda=1 
+ Fold10: alpha=1, lambda=1 
- Fold10: alpha=1, lambda=1 
+ Fold11: alpha=1, lambda=1 
- Fold11: alpha=1, lambda=1 
+ Fold12: alpha=1, lambda=1 
- Fold12: alpha=1, lambda=1 
+ Fold13: alpha=1, lambda=1 
- Fold13: alpha=1, lambda=1 
+ Fold14: alpha=1, lambda=1 
- Fold14: alpha=1, lambda=1 
+ Fold15: alpha=1, lambda=1 
- Fold15: alpha=1, lambda=1 
+ Fold16: alpha=1, lambda=1 
- Fold16: alpha=1, lambda=1 
+ Fold17: alpha=1, lambda=1 
- Fold17: alpha=1, lambda=1 
+ Fold18: alpha=1, lambda=1 
- Fold18: alpha=1, lambda=1 
+ Fold19: alpha=1, lambda=1 
- Fold19: alpha=1, lambda=1 
+ Fold20: alpha=1, lambda=1 
- Fold20: alpha=1, lambda=1 
+ Fold21: alpha=1, lambda=1 
- Fold21: alpha=1, lambda=1 
+ Fold22: alpha=1, lambda=1 
- Fold22: alpha=1, lambda=1 
+ Fold23: alpha=1, lambda=1 
- Fold23: alpha=1, lambda=1 
+ Fold24: alpha=1, lambda=1 
- Fold24: alpha=1, lambda=1 
+ Fold25: alpha=1, lambda=1 
- Fold25: alpha=1, lambda=1 
+ Fold26: alpha=1, lambda=1 
- Fold26: alpha=1, lambda=1 
+ Fold27: alpha=1, lambda=1 
- Fold27: alpha=1, lambda=1 
+ Fold28: alpha=1, lambda=1 
- Fold28: alpha=1, lambda=1 
+ Fold29: alpha=1, lambda=1 
- Fold29: alpha=1, lambda=1 
+ Fold30: alpha=1, lambda=1 
- Fold30: alpha=1, lambda=1 
+ Fold31: alpha=1, lambda=1 
- Fold31: alpha=1, lambda=1 
+ Fold32: alpha=1, lambda=1 
- Fold32: alpha=1, lambda=1 
+ Fold33: alpha=1, lambda=1 
- Fold33: alpha=1, lambda=1 
+ Fold34: alpha=1, lambda=1 
- Fold34: alpha=1, lambda=1 
+ Fold35: alpha=1, lambda=1 
- Fold35: alpha=1, lambda=1 
Aggregating results
Selecting tuning parameters
Fitting alpha = 1, lambda = 0.071 on full training set</code></pre>
<pre class="r"><code>print(fit)</code></pre>
<pre><code>glmnet 

  35 samples
4501 predictors
   6 classes: &#39;pen1&#39;, &#39;pen2&#39;, &#39;pen3&#39;, &#39;pen4&#39;, &#39;pen5&#39;, &#39;pen6&#39; 

No pre-processing
Resampling: Leave-One-Out Cross-Validation 
Summary of sample sizes: 34, 34, 34, 34, 34, 34, ... 
Resampling results across tuning parameters:

  lambda  Accuracy   Kappa      
  0.001   0.8857143  0.860418744
  0.002   0.8857143  0.860418744
  0.003   0.8857143  0.860418744
  0.004   0.8857143  0.860418744
  0.005   0.8857143  0.860418744
  0.006   0.8857143  0.860418744
  0.007   0.8857143  0.860418744
  0.008   0.8857143  0.860418744
  0.009   0.8857143  0.860418744
  0.010   0.8857143  0.860418744
  0.011   0.8857143  0.860418744
  0.012   0.8857143  0.860418744
  0.013   0.8857143  0.860418744
  0.014   0.8857143  0.860418744
  0.015   0.8857143  0.860418744
  0.016   0.8857143  0.860418744
  0.017   0.8857143  0.860418744
  0.018   0.8857143  0.860418744
  0.019   0.8857143  0.860418744
  0.020   0.8857143  0.860418744
  0.021   0.8857143  0.860418744
  0.022   0.8857143  0.860418744
  0.023   0.8857143  0.860418744
  0.024   0.8857143  0.860418744
  0.025   0.8857143  0.860418744
  0.026   0.8857143  0.860418744
  0.027   0.8857143  0.860418744
  0.028   0.8857143  0.860418744
  0.029   0.8857143  0.860418744
  0.030   0.8857143  0.860418744
  0.031   0.8857143  0.860418744
  0.032   0.8857143  0.860418744
  0.033   0.8857143  0.860418744
  0.034   0.8857143  0.860418744
  0.035   0.8857143  0.860418744
  0.036   0.8857143  0.860418744
  0.037   0.8857143  0.860418744
  0.038   0.8857143  0.860418744
  0.039   0.8857143  0.860418744
  0.040   0.8857143  0.860418744
  0.041   0.8857143  0.860418744
  0.042   0.8857143  0.860418744
  0.043   0.8857143  0.860418744
  0.044   0.8857143  0.860418744
  0.045   0.8857143  0.860418744
  0.046   0.8857143  0.860418744
  0.047   0.8857143  0.860418744
  0.048   0.8857143  0.860418744
  0.049   0.8857143  0.860418744
  0.050   0.8857143  0.860418744
  0.051   0.8857143  0.860418744
  0.052   0.8857143  0.860418744
  0.053   0.8857143  0.860418744
  0.054   0.8857143  0.860418744
  0.055   0.8857143  0.860418744
  0.056   0.8857143  0.860418744
  0.057   0.8857143  0.860418744
  0.058   0.8857143  0.860418744
  0.059   0.8857143  0.860418744
  0.060   0.8857143  0.860418744
  0.061   0.8857143  0.860418744
  0.062   0.8857143  0.860418744
  0.063   0.8857143  0.860418744
  0.064   0.8857143  0.860418744
  0.065   0.8857143  0.860418744
  0.066   0.8857143  0.860418744
  0.067   0.8857143  0.860418744
  0.068   0.8857143  0.860418744
  0.069   0.8857143  0.860418744
  0.070   0.8857143  0.860418744
  0.071   0.8857143  0.860418744
  0.072   0.8571429  0.824824825
  0.073   0.8571429  0.824824825
  0.074   0.8571429  0.824824825
  0.075   0.8571429  0.824824825
  0.076   0.8285714  0.789156627
  0.077   0.8285714  0.789156627
  0.078   0.8285714  0.789156627
  0.079   0.8285714  0.789156627
  0.080   0.8285714  0.789156627
  0.081   0.8285714  0.789156627
  0.082   0.8285714  0.789156627
  0.083   0.8285714  0.789156627
  0.084   0.8285714  0.789156627
  0.085   0.8285714  0.789156627
  0.086   0.8285714  0.789156627
  0.087   0.8285714  0.789156627
  0.088   0.8285714  0.789156627
  0.089   0.8285714  0.789156627
  0.090   0.8285714  0.789156627
  0.091   0.8285714  0.789156627
  0.092   0.8285714  0.789156627
  0.093   0.8285714  0.789156627
  0.094   0.8285714  0.789156627
  0.095   0.8285714  0.789156627
  0.096   0.8285714  0.789156627
  0.097   0.8285714  0.789156627
  0.098   0.8285714  0.789156627
  0.099   0.8285714  0.789156627
  0.100   0.8285714  0.789156627
  0.101   0.8285714  0.789156627
  0.102   0.8285714  0.789156627
  0.103   0.8285714  0.789156627
  0.104   0.8285714  0.789156627
  0.105   0.8285714  0.789156627
  0.106   0.8285714  0.789156627
  0.107   0.8285714  0.789156627
  0.108   0.8285714  0.789156627
  0.109   0.8285714  0.789156627
  0.110   0.8285714  0.789156627
  0.111   0.8285714  0.789156627
  0.112   0.8285714  0.789156627
  0.113   0.8285714  0.789156627
  0.114   0.8285714  0.789156627
  0.115   0.8285714  0.789156627
  0.116   0.8285714  0.789156627
  0.117   0.8285714  0.789156627
  0.118   0.8285714  0.789156627
  0.119   0.8285714  0.789156627
  0.120   0.8285714  0.789156627
  0.121   0.8285714  0.789156627
  0.122   0.8285714  0.789156627
  0.123   0.8285714  0.789156627
  0.124   0.8285714  0.789156627
  0.125   0.8285714  0.789156627
  0.126   0.8285714  0.789156627
  0.127   0.8285714  0.788519637
  0.128   0.8285714  0.788519637
  0.129   0.8285714  0.788519637
  0.130   0.8285714  0.788519637
  0.131   0.8285714  0.788519637
  0.132   0.8285714  0.788519637
  0.133   0.8285714  0.788519637
  0.134   0.8000000  0.754262788
  0.135   0.8000000  0.754262788
  0.136   0.8000000  0.754262788
  0.137   0.8000000  0.754262788
  0.138   0.8000000  0.754262788
  0.139   0.8000000  0.754262788
  0.140   0.8000000  0.754262788
  0.141   0.8000000  0.754262788
  0.142   0.8000000  0.754262788
  0.143   0.8000000  0.754262788
  0.144   0.8000000  0.754262788
  0.145   0.8000000  0.754262788
  0.146   0.8000000  0.754262788
  0.147   0.8000000  0.754262788
  0.148   0.8000000  0.754262788
  0.149   0.7714286  0.718026183
  0.150   0.7714286  0.718026183
  0.151   0.7714286  0.718026183
  0.152   0.7714286  0.718026183
  0.153   0.7714286  0.718026183
  0.154   0.7714286  0.718026183
  0.155   0.7714286  0.718026183
  0.156   0.7714286  0.718026183
  0.157   0.7714286  0.718026183
  0.158   0.7714286  0.718026183
  0.159   0.7714286  0.718026183
  0.160   0.7714286  0.718026183
  0.161   0.7714286  0.718026183
  0.162   0.7714286  0.718026183
  0.163   0.7714286  0.718026183
  0.164   0.7714286  0.718026183
  0.165   0.7714286  0.718026183
  0.166   0.7714286  0.718026183
  0.167   0.7714286  0.718026183
  0.168   0.7714286  0.718026183
  0.169   0.7714286  0.718026183
  0.170   0.7714286  0.718026183
  0.171   0.7714286  0.718026183
  0.172   0.8000000  0.754262788
  0.173   0.8000000  0.754262788
  0.174   0.8000000  0.754262788
  0.175   0.8000000  0.754262788
  0.176   0.8000000  0.754262788
  0.177   0.8000000  0.754262788
  0.178   0.8000000  0.754262788
  0.179   0.7714286  0.718026183
  0.180   0.7714286  0.718026183
  0.181   0.7714286  0.718026183
  0.182   0.7714286  0.718026183
  0.183   0.8000000  0.753521127
  0.184   0.8000000  0.753521127
  0.185   0.8000000  0.753521127
  0.186   0.8000000  0.753521127
  0.187   0.8000000  0.753521127
  0.188   0.8000000  0.753521127
  0.189   0.7714286  0.717171717
  0.190   0.7714286  0.717171717
  0.191   0.7714286  0.717171717
  0.192   0.7714286  0.717171717
  0.193   0.7714286  0.717171717
  0.194   0.7428571  0.680527383
  0.195   0.7428571  0.680527383
  0.196   0.7428571  0.680527383
  0.197   0.7142857  0.643584521
  0.198   0.7142857  0.643584521
  0.199   0.7142857  0.643584521
  0.200   0.7142857  0.643584521
  0.201   0.7142857  0.643584521
  0.202   0.7142857  0.643584521
  0.203   0.7142857  0.643584521
  0.204   0.7142857  0.643584521
  0.205   0.7142857  0.643584521
  0.206   0.7142857  0.643584521
  0.207   0.7142857  0.643584521
  0.208   0.7142857  0.643584521
  0.209   0.7142857  0.643584521
  0.210   0.7142857  0.643584521
  0.211   0.7142857  0.643584521
  0.212   0.7142857  0.643584521
  0.213   0.7142857  0.643584521
  0.214   0.7142857  0.643584521
  0.215   0.7142857  0.643584521
  0.216   0.7142857  0.643584521
  0.217   0.7142857  0.643584521
  0.218   0.7142857  0.643584521
  0.219   0.7142857  0.643584521
  0.220   0.7142857  0.643584521
  0.221   0.7142857  0.643584521
  0.222   0.7142857  0.643584521
  0.223   0.7142857  0.643584521
  0.224   0.7142857  0.643584521
  0.225   0.7142857  0.643584521
  0.226   0.7142857  0.643584521
  0.227   0.7142857  0.643584521
  0.228   0.7142857  0.643584521
  0.229   0.7142857  0.643584521
  0.230   0.7428571  0.677914110
  0.231   0.7428571  0.677914110
  0.232   0.7428571  0.677914110
  0.233   0.7428571  0.677914110
  0.234   0.7428571  0.677914110
  0.235   0.7428571  0.677914110
  0.236   0.7428571  0.677914110
  0.237   0.7428571  0.677914110
  0.238   0.7428571  0.677914110
  0.239   0.7428571  0.677914110
  0.240   0.7142857  0.640657084
  0.241   0.7142857  0.640657084
  0.242   0.7142857  0.640657084
  0.243   0.7142857  0.640657084
  0.244   0.7142857  0.640657084
  0.245   0.7142857  0.640657084
  0.246   0.7142857  0.640657084
  0.247   0.7142857  0.640657084
  0.248   0.7142857  0.640657084
  0.249   0.7142857  0.640657084
  0.250   0.7142857  0.640657084
  0.251   0.7142857  0.640657084
  0.252   0.7142857  0.640657084
  0.253   0.6857143  0.603092784
  0.254   0.6857143  0.603092784
  0.255   0.6571429  0.565217391
  0.256   0.6285714  0.527027027
  0.257   0.6285714  0.527027027
  0.258   0.6285714  0.527027027
  0.259   0.6285714  0.527027027
  0.260   0.6000000  0.488517745
  0.261   0.6000000  0.488517745
  0.262   0.6000000  0.488517745
  0.263   0.6000000  0.488517745
  0.264   0.6000000  0.488517745
  0.265   0.5714286  0.449685535
  0.266   0.5714286  0.449685535
  0.267   0.5428571  0.410526316
  0.268   0.5428571  0.410526316
  0.269   0.5428571  0.410526316
  0.270   0.5428571  0.410526316
  0.271   0.5428571  0.410526316
  0.272   0.5142857  0.371700106
  0.273   0.4857143  0.332627119
  0.274   0.4571429  0.292553191
  0.275   0.4571429  0.292553191
  0.276   0.4571429  0.292553191
  0.277   0.4571429  0.292553191
  0.278   0.4000000  0.212218650
  0.279   0.3714286  0.171151776
  0.280   0.3428571  0.129729730
  0.281   0.3142857  0.088937093
  0.282   0.2571429  0.004376368
  0.283   0.2571429  0.004376368
  0.284   0.2571429  0.004376368
  0.285   0.2571429  0.004376368
  0.286   0.2571429  0.004376368
  0.287   0.2571429  0.004376368
  0.288   0.2571429  0.004376368
  0.289   0.2571429  0.004376368
  0.290   0.2571429  0.004376368
  0.291   0.2571429  0.004376368
  0.292   0.2571429  0.004376368
  0.293   0.2571429  0.004376368
  0.294   0.2571429  0.004376368
  0.295   0.2571429  0.004376368
  0.296   0.2571429  0.004376368
  0.297   0.2571429  0.004376368
  0.298   0.2571429  0.004376368
  0.299   0.2571429  0.004376368
  0.300   0.2571429  0.004376368
  0.301   0.2571429  0.004376368
  0.302   0.2571429  0.004376368
  0.303   0.2571429  0.004376368
  0.304   0.2571429  0.004376368
  0.305   0.2571429  0.004376368
  0.306   0.2571429  0.004376368
  0.307   0.2571429  0.004376368
  0.308   0.2571429  0.004376368
  0.309   0.2571429  0.004376368
  0.310   0.2571429  0.004376368
  0.311   0.2571429  0.004376368
  0.312   0.2571429  0.000000000
  0.313   0.2571429  0.000000000
  0.314   0.2571429  0.000000000
  0.315   0.2571429  0.000000000
  0.316   0.2571429  0.000000000
  0.317   0.2571429  0.000000000
  0.318   0.2571429  0.000000000
  0.319   0.2571429  0.000000000
  0.320   0.2571429  0.000000000
  0.321   0.2571429  0.000000000
  0.322   0.2571429  0.000000000
  0.323   0.2571429  0.000000000
  0.324   0.2571429  0.000000000
  0.325   0.2571429  0.000000000
  0.326   0.2571429  0.000000000
  0.327   0.2571429  0.000000000
  0.328   0.2571429  0.000000000
  0.329   0.2571429  0.000000000
  0.330   0.2571429  0.000000000
  0.331   0.2571429  0.000000000
  0.332   0.2571429  0.000000000
  0.333   0.2571429  0.000000000
  0.334   0.2571429  0.000000000
  0.335   0.2571429  0.000000000
  0.336   0.2571429  0.000000000
  0.337   0.2571429  0.000000000
  0.338   0.2571429  0.000000000
  0.339   0.2571429  0.000000000
  0.340   0.2571429  0.000000000
  0.341   0.2571429  0.000000000
  0.342   0.2571429  0.000000000
  0.343   0.2571429  0.000000000
  0.344   0.2571429  0.000000000
  0.345   0.2571429  0.000000000
  0.346   0.2571429  0.000000000
  0.347   0.2571429  0.000000000
  0.348   0.2571429  0.000000000
  0.349   0.2571429  0.000000000
  0.350   0.2571429  0.000000000
  0.351   0.2571429  0.000000000
  0.352   0.2571429  0.000000000
  0.353   0.2571429  0.000000000
  0.354   0.2571429  0.000000000
  0.355   0.2571429  0.000000000
  0.356   0.2571429  0.000000000
  0.357   0.2571429  0.000000000
  0.358   0.2571429  0.000000000
  0.359   0.2571429  0.000000000
  0.360   0.2571429  0.000000000
  0.361   0.2571429  0.000000000
  0.362   0.2571429  0.000000000
  0.363   0.2571429  0.000000000
  0.364   0.2571429  0.000000000
  0.365   0.2571429  0.000000000
  0.366   0.2571429  0.000000000
  0.367   0.2571429  0.000000000
  0.368   0.2571429  0.000000000
  0.369   0.2571429  0.000000000
  0.370   0.2571429  0.000000000
  0.371   0.2571429  0.000000000
  0.372   0.2571429  0.000000000
  0.373   0.2571429  0.000000000
  0.374   0.2571429  0.000000000
  0.375   0.2571429  0.000000000
  0.376   0.2571429  0.000000000
  0.377   0.2571429  0.000000000
  0.378   0.2571429  0.000000000
  0.379   0.2571429  0.000000000
  0.380   0.2571429  0.000000000
  0.381   0.2571429  0.000000000
  0.382   0.2571429  0.000000000
  0.383   0.2571429  0.000000000
  0.384   0.2571429  0.000000000
  0.385   0.2571429  0.000000000
  0.386   0.2571429  0.000000000
  0.387   0.2571429  0.000000000
  0.388   0.2571429  0.000000000
  0.389   0.2571429  0.000000000
  0.390   0.2571429  0.000000000
  0.391   0.2571429  0.000000000
  0.392   0.2571429  0.000000000
  0.393   0.2571429  0.000000000
  0.394   0.2571429  0.000000000
  0.395   0.2571429  0.000000000
  0.396   0.2571429  0.000000000
  0.397   0.2571429  0.000000000
  0.398   0.2571429  0.000000000
  0.399   0.2571429  0.000000000
  0.400   0.2571429  0.000000000
  0.401   0.2571429  0.000000000
  0.402   0.2571429  0.000000000
  0.403   0.2571429  0.000000000
  0.404   0.2571429  0.000000000
  0.405   0.2571429  0.000000000
  0.406   0.2571429  0.000000000
  0.407   0.2571429  0.000000000
  0.408   0.2571429  0.000000000
  0.409   0.2571429  0.000000000
  0.410   0.2571429  0.000000000
  0.411   0.2571429  0.000000000
  0.412   0.2571429  0.000000000
  0.413   0.2571429  0.000000000
  0.414   0.2571429  0.000000000
  0.415   0.2571429  0.000000000
  0.416   0.2571429  0.000000000
  0.417   0.2571429  0.000000000
  0.418   0.2571429  0.000000000
  0.419   0.2571429  0.000000000
  0.420   0.2571429  0.000000000
  0.421   0.2571429  0.000000000
  0.422   0.2571429  0.000000000
  0.423   0.2571429  0.000000000
  0.424   0.2571429  0.000000000
  0.425   0.2571429  0.000000000
  0.426   0.2571429  0.000000000
  0.427   0.2571429  0.000000000
  0.428   0.2571429  0.000000000
  0.429   0.2571429  0.000000000
  0.430   0.2571429  0.000000000
  0.431   0.2571429  0.000000000
  0.432   0.2571429  0.000000000
  0.433   0.2571429  0.000000000
  0.434   0.2571429  0.000000000
  0.435   0.2571429  0.000000000
  0.436   0.2571429  0.000000000
  0.437   0.2571429  0.000000000
  0.438   0.2571429  0.000000000
  0.439   0.2571429  0.000000000
  0.440   0.2571429  0.000000000
  0.441   0.2571429  0.000000000
  0.442   0.2571429  0.000000000
  0.443   0.2571429  0.000000000
  0.444   0.2571429  0.000000000
  0.445   0.2571429  0.000000000
  0.446   0.2571429  0.000000000
  0.447   0.2571429  0.000000000
  0.448   0.2571429  0.000000000
  0.449   0.2571429  0.000000000
  0.450   0.2571429  0.000000000
  0.451   0.2571429  0.000000000
  0.452   0.2571429  0.000000000
  0.453   0.2571429  0.000000000
  0.454   0.2571429  0.000000000
  0.455   0.2571429  0.000000000
  0.456   0.2571429  0.000000000
  0.457   0.2571429  0.000000000
  0.458   0.2571429  0.000000000
  0.459   0.2571429  0.000000000
  0.460   0.2571429  0.000000000
  0.461   0.2571429  0.000000000
  0.462   0.2571429  0.000000000
  0.463   0.2571429  0.000000000
  0.464   0.2571429  0.000000000
  0.465   0.2571429  0.000000000
  0.466   0.2571429  0.000000000
  0.467   0.2571429  0.000000000
  0.468   0.2571429  0.000000000
  0.469   0.2571429  0.000000000
  0.470   0.2571429  0.000000000
  0.471   0.2571429  0.000000000
  0.472   0.2571429  0.000000000
  0.473   0.2571429  0.000000000
  0.474   0.2571429  0.000000000
  0.475   0.2571429  0.000000000
  0.476   0.2571429  0.000000000
  0.477   0.2571429  0.000000000
  0.478   0.2571429  0.000000000
  0.479   0.2571429  0.000000000
  0.480   0.2571429  0.000000000
  0.481   0.2571429  0.000000000
  0.482   0.2571429  0.000000000
  0.483   0.2571429  0.000000000
  0.484   0.2571429  0.000000000
  0.485   0.2571429  0.000000000
  0.486   0.2571429  0.000000000
  0.487   0.2571429  0.000000000
  0.488   0.2571429  0.000000000
  0.489   0.2571429  0.000000000
  0.490   0.2571429  0.000000000
  0.491   0.2571429  0.000000000
  0.492   0.2571429  0.000000000
  0.493   0.2571429  0.000000000
  0.494   0.2571429  0.000000000
  0.495   0.2571429  0.000000000
  0.496   0.2571429  0.000000000
  0.497   0.2571429  0.000000000
  0.498   0.2571429  0.000000000
  0.499   0.2571429  0.000000000
  0.500   0.2571429  0.000000000
  0.501   0.2571429  0.000000000
  0.502   0.2571429  0.000000000
  0.503   0.2571429  0.000000000
  0.504   0.2571429  0.000000000
  0.505   0.2571429  0.000000000
  0.506   0.2571429  0.000000000
  0.507   0.2571429  0.000000000
  0.508   0.2571429  0.000000000
  0.509   0.2571429  0.000000000
  0.510   0.2571429  0.000000000
  0.511   0.2571429  0.000000000
  0.512   0.2571429  0.000000000
  0.513   0.2571429  0.000000000
  0.514   0.2571429  0.000000000
  0.515   0.2571429  0.000000000
  0.516   0.2571429  0.000000000
  0.517   0.2571429  0.000000000
  0.518   0.2571429  0.000000000
  0.519   0.2571429  0.000000000
  0.520   0.2571429  0.000000000
  0.521   0.2571429  0.000000000
  0.522   0.2571429  0.000000000
  0.523   0.2571429  0.000000000
  0.524   0.2571429  0.000000000
  0.525   0.2571429  0.000000000
  0.526   0.2571429  0.000000000
  0.527   0.2571429  0.000000000
  0.528   0.2571429  0.000000000
  0.529   0.2571429  0.000000000
  0.530   0.2571429  0.000000000
  0.531   0.2571429  0.000000000
  0.532   0.2571429  0.000000000
  0.533   0.2571429  0.000000000
  0.534   0.2571429  0.000000000
  0.535   0.2571429  0.000000000
  0.536   0.2571429  0.000000000
  0.537   0.2571429  0.000000000
  0.538   0.2571429  0.000000000
  0.539   0.2571429  0.000000000
  0.540   0.2571429  0.000000000
  0.541   0.2571429  0.000000000
  0.542   0.2571429  0.000000000
  0.543   0.2571429  0.000000000
  0.544   0.2571429  0.000000000
  0.545   0.2571429  0.000000000
  0.546   0.2571429  0.000000000
  0.547   0.2571429  0.000000000
  0.548   0.2571429  0.000000000
  0.549   0.2571429  0.000000000
  0.550   0.2571429  0.000000000
  0.551   0.2571429  0.000000000
  0.552   0.2571429  0.000000000
  0.553   0.2571429  0.000000000
  0.554   0.2571429  0.000000000
  0.555   0.2571429  0.000000000
  0.556   0.2571429  0.000000000
  0.557   0.2571429  0.000000000
  0.558   0.2571429  0.000000000
  0.559   0.2571429  0.000000000
  0.560   0.2571429  0.000000000
  0.561   0.2571429  0.000000000
  0.562   0.2571429  0.000000000
  0.563   0.2571429  0.000000000
  0.564   0.2571429  0.000000000
  0.565   0.2571429  0.000000000
  0.566   0.2571429  0.000000000
  0.567   0.2571429  0.000000000
  0.568   0.2571429  0.000000000
  0.569   0.2571429  0.000000000
  0.570   0.2571429  0.000000000
  0.571   0.2571429  0.000000000
  0.572   0.2571429  0.000000000
  0.573   0.2571429  0.000000000
  0.574   0.2571429  0.000000000
  0.575   0.2571429  0.000000000
  0.576   0.2571429  0.000000000
  0.577   0.2571429  0.000000000
  0.578   0.2571429  0.000000000
  0.579   0.2571429  0.000000000
  0.580   0.2571429  0.000000000
  0.581   0.2571429  0.000000000
  0.582   0.2571429  0.000000000
  0.583   0.2571429  0.000000000
  0.584   0.2571429  0.000000000
  0.585   0.2571429  0.000000000
  0.586   0.2571429  0.000000000
  0.587   0.2571429  0.000000000
  0.588   0.2571429  0.000000000
  0.589   0.2571429  0.000000000
  0.590   0.2571429  0.000000000
  0.591   0.2571429  0.000000000
  0.592   0.2571429  0.000000000
  0.593   0.2571429  0.000000000
  0.594   0.2571429  0.000000000
  0.595   0.2571429  0.000000000
  0.596   0.2571429  0.000000000
  0.597   0.2571429  0.000000000
  0.598   0.2571429  0.000000000
  0.599   0.2571429  0.000000000
  0.600   0.2571429  0.000000000
  0.601   0.2571429  0.000000000
  0.602   0.2571429  0.000000000
  0.603   0.2571429  0.000000000
  0.604   0.2571429  0.000000000
  0.605   0.2571429  0.000000000
  0.606   0.2571429  0.000000000
  0.607   0.2571429  0.000000000
  0.608   0.2571429  0.000000000
  0.609   0.2571429  0.000000000
  0.610   0.2571429  0.000000000
  0.611   0.2571429  0.000000000
  0.612   0.2571429  0.000000000
  0.613   0.2571429  0.000000000
  0.614   0.2571429  0.000000000
  0.615   0.2571429  0.000000000
  0.616   0.2571429  0.000000000
  0.617   0.2571429  0.000000000
  0.618   0.2571429  0.000000000
  0.619   0.2571429  0.000000000
  0.620   0.2571429  0.000000000
  0.621   0.2571429  0.000000000
  0.622   0.2571429  0.000000000
  0.623   0.2571429  0.000000000
  0.624   0.2571429  0.000000000
  0.625   0.2571429  0.000000000
  0.626   0.2571429  0.000000000
  0.627   0.2571429  0.000000000
  0.628   0.2571429  0.000000000
  0.629   0.2571429  0.000000000
  0.630   0.2571429  0.000000000
  0.631   0.2571429  0.000000000
  0.632   0.2571429  0.000000000
  0.633   0.2571429  0.000000000
  0.634   0.2571429  0.000000000
  0.635   0.2571429  0.000000000
  0.636   0.2571429  0.000000000
  0.637   0.2571429  0.000000000
  0.638   0.2571429  0.000000000
  0.639   0.2571429  0.000000000
  0.640   0.2571429  0.000000000
  0.641   0.2571429  0.000000000
  0.642   0.2571429  0.000000000
  0.643   0.2571429  0.000000000
  0.644   0.2571429  0.000000000
  0.645   0.2571429  0.000000000
  0.646   0.2571429  0.000000000
  0.647   0.2571429  0.000000000
  0.648   0.2571429  0.000000000
  0.649   0.2571429  0.000000000
  0.650   0.2571429  0.000000000
  0.651   0.2571429  0.000000000
  0.652   0.2571429  0.000000000
  0.653   0.2571429  0.000000000
  0.654   0.2571429  0.000000000
  0.655   0.2571429  0.000000000
  0.656   0.2571429  0.000000000
  0.657   0.2571429  0.000000000
  0.658   0.2571429  0.000000000
  0.659   0.2571429  0.000000000
  0.660   0.2571429  0.000000000
  0.661   0.2571429  0.000000000
  0.662   0.2571429  0.000000000
  0.663   0.2571429  0.000000000
  0.664   0.2571429  0.000000000
  0.665   0.2571429  0.000000000
  0.666   0.2571429  0.000000000
  0.667   0.2571429  0.000000000
  0.668   0.2571429  0.000000000
  0.669   0.2571429  0.000000000
  0.670   0.2571429  0.000000000
  0.671   0.2571429  0.000000000
  0.672   0.2571429  0.000000000
  0.673   0.2571429  0.000000000
  0.674   0.2571429  0.000000000
  0.675   0.2571429  0.000000000
  0.676   0.2571429  0.000000000
  0.677   0.2571429  0.000000000
  0.678   0.2571429  0.000000000
  0.679   0.2571429  0.000000000
  0.680   0.2571429  0.000000000
  0.681   0.2571429  0.000000000
  0.682   0.2571429  0.000000000
  0.683   0.2571429  0.000000000
  0.684   0.2571429  0.000000000
  0.685   0.2571429  0.000000000
  0.686   0.2571429  0.000000000
  0.687   0.2571429  0.000000000
  0.688   0.2571429  0.000000000
  0.689   0.2571429  0.000000000
  0.690   0.2571429  0.000000000
  0.691   0.2571429  0.000000000
  0.692   0.2571429  0.000000000
  0.693   0.2571429  0.000000000
  0.694   0.2571429  0.000000000
  0.695   0.2571429  0.000000000
  0.696   0.2571429  0.000000000
  0.697   0.2571429  0.000000000
  0.698   0.2571429  0.000000000
  0.699   0.2571429  0.000000000
  0.700   0.2571429  0.000000000
  0.701   0.2571429  0.000000000
  0.702   0.2571429  0.000000000
  0.703   0.2571429  0.000000000
  0.704   0.2571429  0.000000000
  0.705   0.2571429  0.000000000
  0.706   0.2571429  0.000000000
  0.707   0.2571429  0.000000000
  0.708   0.2571429  0.000000000
  0.709   0.2571429  0.000000000
  0.710   0.2571429  0.000000000
  0.711   0.2571429  0.000000000
  0.712   0.2571429  0.000000000
  0.713   0.2571429  0.000000000
  0.714   0.2571429  0.000000000
  0.715   0.2571429  0.000000000
  0.716   0.2571429  0.000000000
  0.717   0.2571429  0.000000000
  0.718   0.2571429  0.000000000
  0.719   0.2571429  0.000000000
  0.720   0.2571429  0.000000000
  0.721   0.2571429  0.000000000
  0.722   0.2571429  0.000000000
  0.723   0.2571429  0.000000000
  0.724   0.2571429  0.000000000
  0.725   0.2571429  0.000000000
  0.726   0.2571429  0.000000000
  0.727   0.2571429  0.000000000
  0.728   0.2571429  0.000000000
  0.729   0.2571429  0.000000000
  0.730   0.2571429  0.000000000
  0.731   0.2571429  0.000000000
  0.732   0.2571429  0.000000000
  0.733   0.2571429  0.000000000
  0.734   0.2571429  0.000000000
  0.735   0.2571429  0.000000000
  0.736   0.2571429  0.000000000
  0.737   0.2571429  0.000000000
  0.738   0.2571429  0.000000000
  0.739   0.2571429  0.000000000
  0.740   0.2571429  0.000000000
  0.741   0.2571429  0.000000000
  0.742   0.2571429  0.000000000
  0.743   0.2571429  0.000000000
  0.744   0.2571429  0.000000000
  0.745   0.2571429  0.000000000
  0.746   0.2571429  0.000000000
  0.747   0.2571429  0.000000000
  0.748   0.2571429  0.000000000
  0.749   0.2571429  0.000000000
  0.750   0.2571429  0.000000000
  0.751   0.2571429  0.000000000
  0.752   0.2571429  0.000000000
  0.753   0.2571429  0.000000000
  0.754   0.2571429  0.000000000
  0.755   0.2571429  0.000000000
  0.756   0.2571429  0.000000000
  0.757   0.2571429  0.000000000
  0.758   0.2571429  0.000000000
  0.759   0.2571429  0.000000000
  0.760   0.2571429  0.000000000
  0.761   0.2571429  0.000000000
  0.762   0.2571429  0.000000000
  0.763   0.2571429  0.000000000
  0.764   0.2571429  0.000000000
  0.765   0.2571429  0.000000000
  0.766   0.2571429  0.000000000
  0.767   0.2571429  0.000000000
  0.768   0.2571429  0.000000000
  0.769   0.2571429  0.000000000
  0.770   0.2571429  0.000000000
  0.771   0.2571429  0.000000000
  0.772   0.2571429  0.000000000
  0.773   0.2571429  0.000000000
  0.774   0.2571429  0.000000000
  0.775   0.2571429  0.000000000
  0.776   0.2571429  0.000000000
  0.777   0.2571429  0.000000000
  0.778   0.2571429  0.000000000
  0.779   0.2571429  0.000000000
  0.780   0.2571429  0.000000000
  0.781   0.2571429  0.000000000
  0.782   0.2571429  0.000000000
  0.783   0.2571429  0.000000000
  0.784   0.2571429  0.000000000
  0.785   0.2571429  0.000000000
  0.786   0.2571429  0.000000000
  0.787   0.2571429  0.000000000
  0.788   0.2571429  0.000000000
  0.789   0.2571429  0.000000000
  0.790   0.2571429  0.000000000
  0.791   0.2571429  0.000000000
  0.792   0.2571429  0.000000000
  0.793   0.2571429  0.000000000
  0.794   0.2571429  0.000000000
  0.795   0.2571429  0.000000000
  0.796   0.2571429  0.000000000
  0.797   0.2571429  0.000000000
  0.798   0.2571429  0.000000000
  0.799   0.2571429  0.000000000
  0.800   0.2571429  0.000000000
  0.801   0.2571429  0.000000000
  0.802   0.2571429  0.000000000
  0.803   0.2571429  0.000000000
  0.804   0.2571429  0.000000000
  0.805   0.2571429  0.000000000
  0.806   0.2571429  0.000000000
  0.807   0.2571429  0.000000000
  0.808   0.2571429  0.000000000
  0.809   0.2571429  0.000000000
  0.810   0.2571429  0.000000000
  0.811   0.2571429  0.000000000
  0.812   0.2571429  0.000000000
  0.813   0.2571429  0.000000000
  0.814   0.2571429  0.000000000
  0.815   0.2571429  0.000000000
  0.816   0.2571429  0.000000000
  0.817   0.2571429  0.000000000
  0.818   0.2571429  0.000000000
  0.819   0.2571429  0.000000000
  0.820   0.2571429  0.000000000
  0.821   0.2571429  0.000000000
  0.822   0.2571429  0.000000000
  0.823   0.2571429  0.000000000
  0.824   0.2571429  0.000000000
  0.825   0.2571429  0.000000000
  0.826   0.2571429  0.000000000
  0.827   0.2571429  0.000000000
  0.828   0.2571429  0.000000000
  0.829   0.2571429  0.000000000
  0.830   0.2571429  0.000000000
  0.831   0.2571429  0.000000000
  0.832   0.2571429  0.000000000
  0.833   0.2571429  0.000000000
  0.834   0.2571429  0.000000000
  0.835   0.2571429  0.000000000
  0.836   0.2571429  0.000000000
  0.837   0.2571429  0.000000000
  0.838   0.2571429  0.000000000
  0.839   0.2571429  0.000000000
  0.840   0.2571429  0.000000000
  0.841   0.2571429  0.000000000
  0.842   0.2571429  0.000000000
  0.843   0.2571429  0.000000000
  0.844   0.2571429  0.000000000
  0.845   0.2571429  0.000000000
  0.846   0.2571429  0.000000000
  0.847   0.2571429  0.000000000
  0.848   0.2571429  0.000000000
  0.849   0.2571429  0.000000000
  0.850   0.2571429  0.000000000
  0.851   0.2571429  0.000000000
  0.852   0.2571429  0.000000000
  0.853   0.2571429  0.000000000
  0.854   0.2571429  0.000000000
  0.855   0.2571429  0.000000000
  0.856   0.2571429  0.000000000
  0.857   0.2571429  0.000000000
  0.858   0.2571429  0.000000000
  0.859   0.2571429  0.000000000
  0.860   0.2571429  0.000000000
  0.861   0.2571429  0.000000000
  0.862   0.2571429  0.000000000
  0.863   0.2571429  0.000000000
  0.864   0.2571429  0.000000000
  0.865   0.2571429  0.000000000
  0.866   0.2571429  0.000000000
  0.867   0.2571429  0.000000000
  0.868   0.2571429  0.000000000
  0.869   0.2571429  0.000000000
  0.870   0.2571429  0.000000000
  0.871   0.2571429  0.000000000
  0.872   0.2571429  0.000000000
  0.873   0.2571429  0.000000000
  0.874   0.2571429  0.000000000
  0.875   0.2571429  0.000000000
  0.876   0.2571429  0.000000000
  0.877   0.2571429  0.000000000
  0.878   0.2571429  0.000000000
  0.879   0.2571429  0.000000000
  0.880   0.2571429  0.000000000
  0.881   0.2571429  0.000000000
  0.882   0.2571429  0.000000000
  0.883   0.2571429  0.000000000
  0.884   0.2571429  0.000000000
  0.885   0.2571429  0.000000000
  0.886   0.2571429  0.000000000
  0.887   0.2571429  0.000000000
  0.888   0.2571429  0.000000000
  0.889   0.2571429  0.000000000
  0.890   0.2571429  0.000000000
  0.891   0.2571429  0.000000000
  0.892   0.2571429  0.000000000
  0.893   0.2571429  0.000000000
  0.894   0.2571429  0.000000000
  0.895   0.2571429  0.000000000
  0.896   0.2571429  0.000000000
  0.897   0.2571429  0.000000000
  0.898   0.2571429  0.000000000
  0.899   0.2571429  0.000000000
  0.900   0.2571429  0.000000000
  0.901   0.2571429  0.000000000
  0.902   0.2571429  0.000000000
  0.903   0.2571429  0.000000000
  0.904   0.2571429  0.000000000
  0.905   0.2571429  0.000000000
  0.906   0.2571429  0.000000000
  0.907   0.2571429  0.000000000
  0.908   0.2571429  0.000000000
  0.909   0.2571429  0.000000000
  0.910   0.2571429  0.000000000
  0.911   0.2571429  0.000000000
  0.912   0.2571429  0.000000000
  0.913   0.2571429  0.000000000
  0.914   0.2571429  0.000000000
  0.915   0.2571429  0.000000000
  0.916   0.2571429  0.000000000
  0.917   0.2571429  0.000000000
  0.918   0.2571429  0.000000000
  0.919   0.2571429  0.000000000
  0.920   0.2571429  0.000000000
  0.921   0.2571429  0.000000000
  0.922   0.2571429  0.000000000
  0.923   0.2571429  0.000000000
  0.924   0.2571429  0.000000000
  0.925   0.2571429  0.000000000
  0.926   0.2571429  0.000000000
  0.927   0.2571429  0.000000000
  0.928   0.2571429  0.000000000
  0.929   0.2571429  0.000000000
  0.930   0.2571429  0.000000000
  0.931   0.2571429  0.000000000
  0.932   0.2571429  0.000000000
  0.933   0.2571429  0.000000000
  0.934   0.2571429  0.000000000
  0.935   0.2571429  0.000000000
  0.936   0.2571429  0.000000000
  0.937   0.2571429  0.000000000
  0.938   0.2571429  0.000000000
  0.939   0.2571429  0.000000000
  0.940   0.2571429  0.000000000
  0.941   0.2571429  0.000000000
  0.942   0.2571429  0.000000000
  0.943   0.2571429  0.000000000
  0.944   0.2571429  0.000000000
  0.945   0.2571429  0.000000000
  0.946   0.2571429  0.000000000
  0.947   0.2571429  0.000000000
  0.948   0.2571429  0.000000000
  0.949   0.2571429  0.000000000
  0.950   0.2571429  0.000000000
  0.951   0.2571429  0.000000000
  0.952   0.2571429  0.000000000
  0.953   0.2571429  0.000000000
  0.954   0.2571429  0.000000000
  0.955   0.2571429  0.000000000
  0.956   0.2571429  0.000000000
  0.957   0.2571429  0.000000000
  0.958   0.2571429  0.000000000
  0.959   0.2571429  0.000000000
  0.960   0.2571429  0.000000000
  0.961   0.2571429  0.000000000
  0.962   0.2571429  0.000000000
  0.963   0.2571429  0.000000000
  0.964   0.2571429  0.000000000
  0.965   0.2571429  0.000000000
  0.966   0.2571429  0.000000000
  0.967   0.2571429  0.000000000
  0.968   0.2571429  0.000000000
  0.969   0.2571429  0.000000000
  0.970   0.2571429  0.000000000
  0.971   0.2571429  0.000000000
  0.972   0.2571429  0.000000000
  0.973   0.2571429  0.000000000
  0.974   0.2571429  0.000000000
  0.975   0.2571429  0.000000000
  0.976   0.2571429  0.000000000
  0.977   0.2571429  0.000000000
  0.978   0.2571429  0.000000000
  0.979   0.2571429  0.000000000
  0.980   0.2571429  0.000000000
  0.981   0.2571429  0.000000000
  0.982   0.2571429  0.000000000
  0.983   0.2571429  0.000000000
  0.984   0.2571429  0.000000000
  0.985   0.2571429  0.000000000
  0.986   0.2571429  0.000000000
  0.987   0.2571429  0.000000000
  0.988   0.2571429  0.000000000
  0.989   0.2571429  0.000000000
  0.990   0.2571429  0.000000000
  0.991   0.2571429  0.000000000
  0.992   0.2571429  0.000000000
  0.993   0.2571429  0.000000000
  0.994   0.2571429  0.000000000
  0.995   0.2571429  0.000000000
  0.996   0.2571429  0.000000000
  0.997   0.2571429  0.000000000
  0.998   0.2571429  0.000000000
  0.999   0.2571429  0.000000000
  1.000   0.2571429  0.000000000

Tuning parameter &#39;alpha&#39; was held constant at a value of 1
Accuracy was used to select the optimal model using the largest value.
The final values used for the model were alpha = 1 and lambda = 0.071.</code></pre>
<pre class="r"><code>ggplot(fit)</code></pre>
<p><img src="figure/PiB.Rmd/unnamed-chunk-43-1.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code>(predicted&lt;- predict(fit, newdata = test_data[,-1],type = &quot;prob&quot;))</code></pre>
<pre><code>        pen1       pen2       pen3       pen4       pen5       pen6
1 0.35035770 0.15869050 0.21982481 0.09010285 0.09464762 0.08637652
2 0.46825110 0.41801363 0.03268839 0.01710603 0.03015513 0.03378571
3 0.15831550 0.06818387 0.49334502 0.18507587 0.05083365 0.04424609
4 0.25577386 0.10427895 0.06270645 0.45914064 0.06317212 0.05492797
5 0.07248795 0.21016591 0.08766641 0.16101608 0.40431539 0.06434827
6 0.02196375 0.03094998 0.01804293 0.01635299 0.01747530 0.89521504</code></pre>
<pre class="r"><code>(predicted&lt;- predict(fit, newdata = test_data[,-1]))</code></pre>
<pre><code>[1] pen1 pen1 pen3 pen4 pen5 pen6
Levels: pen1 pen2 pen3 pen4 pen5 pen6</code></pre>
<br>
<p>
<button type="button" class="btn btn-default btn-workflowr btn-workflowr-sessioninfo" data-toggle="collapse" data-target="#workflowr-sessioninfo" style="display: block;">
<span class="glyphicon glyphicon-wrench" aria-hidden="true"></span> Session information
</button>
</p>
<div id="workflowr-sessioninfo" class="collapse">
<pre class="r"><code>sessionInfo()</code></pre>
<pre><code>R version 4.0.4 (2021-02-15)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 10 x64 (build 19043)

Matrix products: default

locale:
[1] LC_COLLATE=Catalan_Spain.1252  LC_CTYPE=Catalan_Spain.1252   
[3] LC_MONETARY=Catalan_Spain.1252 LC_NUMERIC=C                  
[5] LC_TIME=Catalan_Spain.1252    

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
 [1] e1071_1.7-6      caret_6.0-86     lattice_0.20-41  plotly_4.9.3    
 [5] ggpubr_0.4.0     reshape2_1.4.4   Rtsne_0.15       ggfortify_0.4.11
 [9] forcats_0.5.1    stringr_1.4.0    dplyr_1.0.5      purrr_0.3.4     
[13] readr_1.4.0      tidyr_1.1.3      tibble_3.0.3     ggplot2_3.3.3   
[17] tidyverse_1.3.1 

loaded via a namespace (and not attached):
  [1] colorspace_1.4-1     ggsignif_0.6.1       ellipsis_0.3.1      
  [4] class_7.3-17         rio_0.5.26           rprojroot_2.0.2     
  [7] fs_1.5.0             proxy_0.4-25         rstudioapi_0.13     
 [10] farver_2.0.3         prodlim_2019.11.13   fansi_0.4.1         
 [13] lubridate_1.7.10     xml2_1.3.2           codetools_0.2-18    
 [16] splines_4.0.4        knitr_1.30           jsonlite_1.7.2      
 [19] workflowr_1.6.2      pROC_1.17.0.1        broom_0.7.6         
 [22] dbplyr_2.1.1         compiler_4.0.4       httr_1.4.2          
 [25] backports_1.1.10     assertthat_0.2.1     Matrix_1.2-18       
 [28] lazyeval_0.2.2       cli_2.4.0            later_1.1.0.1       
 [31] htmltools_0.5.1.1    tools_4.0.4          gtable_0.3.0        
 [34] glue_1.4.2           Rcpp_1.0.5           carData_3.0-4       
 [37] cellranger_1.1.0     jquerylib_0.1.3      vctrs_0.3.7         
 [40] nlme_3.1-149         iterators_1.0.13     crosstalk_1.1.1     
 [43] timeDate_3043.102    xfun_0.18            gower_0.2.2         
 [46] ps_1.6.0             openxlsx_4.2.3       rvest_1.0.0         
 [49] lifecycle_1.0.0      rstatix_0.7.0        MASS_7.3-53         
 [52] scales_1.1.1         ipred_0.9-10         hms_1.0.0           
 [55] promises_1.2.0.1     RColorBrewer_1.1-2   yaml_2.2.1          
 [58] curl_4.3             gridExtra_2.3        sass_0.3.1          
 [61] rpart_4.1-15         stringi_1.5.3        foreach_1.5.1       
 [64] zip_2.1.1            shape_1.4.5          lava_1.6.9          
 [67] rlang_0.4.10         pkgconfig_2.0.3      evaluate_0.14       
 [70] recipes_0.1.16       htmlwidgets_1.5.3    labeling_0.4.2      
 [73] cowplot_1.1.0        tidyselect_1.1.0     plyr_1.8.6          
 [76] magrittr_2.0.1       R6_2.5.0             generics_0.1.0      
 [79] DBI_1.1.1            pillar_1.6.0         haven_2.3.1         
 [82] whisker_0.4          foreign_0.8-80       withr_2.4.2         
 [85] survival_3.2-7       abind_1.4-5          nnet_7.3-14         
 [88] modelr_0.1.8         crayon_1.4.1         car_3.0-10          
 [91] utf8_1.2.1           rmarkdown_2.7        grid_4.0.4          
 [94] readxl_1.3.1         data.table_1.13.0    git2r_0.28.0        
 [97] ModelMetrics_1.2.2.2 reprex_2.0.0         digest_0.6.25       
[100] httpuv_1.5.5         glmnet_4.1-1         stats4_4.0.4        
[103] munsell_0.5.0        viridisLite_0.4.0    bslib_0.2.4         </code></pre>
</div>
</div>
</div>
</div>


<!-- Adjust MathJax settings so that all math formulae are shown using
TeX fonts only; see
http://docs.mathjax.org/en/latest/configuration.html.  This will make
the presentation more consistent at the cost of the webpage sometimes
taking slightly longer to load. Note that this only works because the
footer is added to webpages before the MathJax javascript. -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    "HTML-CSS": { availableFonts: ["TeX"] }
  });
</script>




</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->

<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
